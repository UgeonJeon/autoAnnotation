{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4263dac8",
   "metadata": {},
   "source": [
    "* annotation list가 아닌 array 형태로 불러오고\n",
    "* torch.tensor 부분 삭제\n",
    "* xywh2xyxy, xyxy2xywh 함수 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f1ebdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob \n",
    "import os.path as osp\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import magic\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/super/endoai/ugeon/autoAnnotation/ocSort/')\n",
    "from ocSort.trackers.ocsort.ocsort import OCSort\n",
    "\n",
    "sys.path.append('/home/super/endoai/ugeon/')\n",
    "from preprocessingData_v3 import verify_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6aab0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xywh2xyxy(x, image_shape = False):\n",
    "    \"\"\"\n",
    "    image_shape = (width, height)\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray)):\n",
    "        x = np.array(x)\n",
    "\n",
    "    # Convert nx4 boxes from [cx, cy, w, h, cls] to [x1, y1, x2, y2, cls] where xy1=top-left, xy2=bottom-right\n",
    "    y = np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    \n",
    "    if image_shape:\n",
    "        y[:,:4] = y[:,:4] * [int(image_shape[0]), int(image_shape[1]),int(image_shape[0]), int(image_shape[1])]\n",
    "    return y\n",
    "\n",
    "\n",
    "def xyxy2xywh(x, image_shape = False):\n",
    "    \"\"\"\n",
    "    image_shape = (width, height)\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(x, (np.ndarray)):\n",
    "        x = np.array(x)\n",
    "\n",
    "    # Convert nx4 boxes from [x1, y1, x2, y2, cls] to [cx, cy, w, h, cls]\n",
    "    y = np.copy(x)\n",
    "    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # center x\n",
    "    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # center y\n",
    "    y[:, 2] = (x[:, 2] - x[:, 0])         # width x\n",
    "    y[:, 3] = (x[:, 3] - x[:, 1])        # width y\n",
    "\n",
    "    if image_shape:    \n",
    "        y[:,:4] = y[:,:4] / [int(image_shape[0]), int(image_shape[1]),int(image_shape[0]), int(image_shape[1])]\n",
    "    return y\n",
    "\n",
    "\n",
    "def IoU( box1, box2):\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "\n",
    "    # obtain x1, y1, x2, y2 of the intersection\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # compute the width and height of the intersection\n",
    "    w = max(0, x2 - x1 + 1)\n",
    "    h = max(0, y2 - y1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    iou = inter / (box1_area + box2_area - inter)\n",
    "    return iou\n",
    "\n",
    "def calculateZOOM(img1, img2, scale_factor = 0.7):\n",
    "    small1 = cv2.resize(img1, None, fx=scale_factor, fy=scale_factor)\n",
    "    small2 = cv2.resize(img2, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(small1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(small2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect keypoints and compute the ORB descriptors\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "    # Match the descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort the matches in the order of their distances\n",
    "    matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "    # Calculate the zoom level\n",
    "    if len(matches) > 4:\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        zoom = np.abs(np.linalg.det(M))\n",
    "    return zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e52435b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoAnnotate:\n",
    "    \n",
    "    def __init__(self, dataset_path):\n",
    "        self.dataset_path = dataset_path\n",
    "    \n",
    "    def prepare_Detection_df(self, recursive = True):\n",
    "        \"\"\"\n",
    "        caution! Only Available for jpg images\n",
    "        \"\"\"\n",
    "        images = sorted(glob(self.dataset_path + '**/*.jpg', recursive = recursive))\n",
    "        img_path_dict = {osp.basename(f) : f for f in images}\n",
    "        img_annote_dict = dict()\n",
    "        image_shape = list(map(int, re.findall('(\\d+)x(\\d+)', magic.from_file(images[0]))[-1]))\n",
    "        for image in images:\n",
    "            img_name = image.split('/')[-1]\n",
    "            try :\n",
    "                with open(image[:-4]+ '.txt', 'r') as f:\n",
    "                    temp = np.asarray(list(map(lambda x: list(np.float64(x.strip().split( )))+ [1], f.readlines())))\n",
    "                    annotation = temp[:,1:]\n",
    "                    annotation = np.append(annotation, temp[:,0]).reshape(1,6)\n",
    "                    annotation = xywh2xyxy(annotation, image_shape)\n",
    "                    img_annote_dict[img_name]= annotation\n",
    "            except :\n",
    "                img_annote_dict[img_name]= np.nan\n",
    "                \n",
    "        df = pd.DataFrame(columns = ['image', 'path','dets', 'pred_forward', 'pred_backward', 'final_pred'])\n",
    "        df['image'] = img_path_dict.keys()\n",
    "        df['path'] = df['image'].apply(lambda x : img_path_dict[x])\n",
    "        df['dets'] = df['image'].apply(lambda x : img_annote_dict[x])\n",
    "        print(f\"found {len(df)} images / shape : {image_shape[0]}x{image_shape[1]}\")\n",
    "        return df.set_index('image'), image_shape\n",
    "\n",
    "    def get_properDets(self, prev_dets, new_dets, tracking_valid_iou=0.5):\n",
    "        valid_idx = []\n",
    "        for idx, prev_det in enumerate(prev_dets):\n",
    "            for new_det in new_dets:\n",
    "                iou = IoU(new_det, prev_det)\n",
    "                if iou >= tracking_valid_iou:\n",
    "                    valid_idx.append(idx)\n",
    "        valid_idx = list(set(valid_idx))\n",
    "        valid_prev_dets = prev_dets[valid_idx]\n",
    "        return valid_prev_dets\n",
    "\n",
    "    \n",
    "    def create_ocSort_tracker(self):\n",
    "        ocsort_forward = OCSort(det_thresh = 0.1, iou_threshold = 0.1, min_hits = 1, delta_t = 7,)\n",
    "        ocsort_backward = OCSort(det_thresh = 0.1, iou_threshold = 0.1, min_hits = 1, delta_t = 7,)\n",
    "        return ocsort_forward, ocsort_backward\n",
    "\n",
    "    \n",
    "    def interpolate(self, tracker, df, direction, tracking_valid_iou, interpolate_count, image_shape):\n",
    "        \"\"\"\n",
    "        direction : forward, backward\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df.set_index('image', inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if direction  == 'forward':\n",
    "            out_df = df.loc[sorted(df.index)]\n",
    "        elif direction  == 'backward':\n",
    "            out_df = df.loc[sorted(df.index, reverse=True)]\n",
    "        \n",
    "        predictable_state = False\n",
    "        prev_Detected = False\n",
    "        prev_img = None\n",
    "        prev_TrueDets = None\n",
    "        prev_TrueDets_xywh = None\n",
    "        zoom_factor = []\n",
    "        predDet_count = 1\n",
    "        interpolate_det_count = 0\n",
    "\n",
    "        for image_name in tqdm(out_df.index):\n",
    "            det = out_df._get_value(image_name, 'dets')\n",
    "            img_path = out_df._get_value(image_name, 'path')\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if isinstance(det, (np.ndarray)) :\n",
    "                if prev_Detected == False:\n",
    "                    prev_Detected = True\n",
    "                    predictable_state = False\n",
    "                elif prev_Detected:\n",
    "                    predictable_state = True\n",
    "\n",
    "                prev_img = img\n",
    "                prev_TrueDets = det\n",
    "                prev_TrueDets_xywh = xyxy2xywh(det, image_shape)\n",
    "                predDet_count = 1\n",
    "                zoom_factor = []\n",
    "                tracker.update(det,img)\n",
    "            else :\n",
    "                det = np.empty((0, 6))\n",
    "                pred_dets = tracker.update(det,img, return_predict = True)\n",
    "                pred_dets = self.get_properDets(pred_dets,prev_TrueDets, tracking_valid_iou)\n",
    "                \n",
    "                if predictable_state and predDet_count < interpolate_count + 1 and len(pred_dets) >=1:\n",
    "                    zoom = calculateZOOM(prev_img, img)\n",
    "                    zoom_factor.append(zoom)\n",
    "                    if zoom >= 0.6 and zoom <= 1.6:\n",
    "                        pred_dets_xywh = xyxy2xywh(pred_dets, image_shape)\n",
    "                        pred_dets_xywh[:,2] = prev_TrueDets_xywh[:,2].max() * np.mean(zoom_factor)\n",
    "                        pred_dets_xywh[:,3] = prev_TrueDets_xywh[:,3].max() * np.mean(zoom_factor)\n",
    "                        _, pred_dets_xywh = verify_annotation(pred_dets_xywh)\n",
    "                        out_df._set_value(image_name, f'pred_{direction}', pred_dets_xywh)        \n",
    "                        predDet_count += 1\n",
    "                        interpolate_det_count += 1\n",
    "                    else:\n",
    "                        predictable_state = False\n",
    "                        zoom_factor = []\n",
    "\n",
    "                prev_img = img\n",
    "                prev_Detected = False\n",
    "\n",
    "#         print(f'interpolated {direction}', interpolate_det_count)\n",
    "        return out_df\n",
    "\n",
    "\n",
    "    def update_autoAnnotate(self, rst_df, tracking_valid_iou):\n",
    "        part_images = rst_df.loc[(rst_df.pred_forward.notna())|(rst_df.pred_backward.notna())].index\n",
    "        for image in part_images:\n",
    "            pred1 = rst_df._get_value(image, 'pred_forward')\n",
    "            pred2 = rst_df._get_value(image, 'pred_backward')\n",
    "\n",
    "            if type(pred1) == float:\n",
    "                rst_df._set_value(image, 'final_pred', pred2)\n",
    "            elif type(pred2) == float:\n",
    "                rst_df._set_value(image, 'final_pred', pred1)\n",
    "\n",
    "            elif len(pred1) == 1 and len(pred2) == 1: \n",
    "                iou = IoU(pred1[0], pred2[0])\n",
    "                if iou >= tracking_valid_iou:\n",
    "                    new_pred = (pred1  + pred2)/2\n",
    "                    _, new_pred = verify_annotation(new_pred)\n",
    "                    rst_df._set_value(image, 'final_pred', new_pred)\n",
    "                else:\n",
    "                    continue\n",
    "        print(f\"{rst_df.final_pred.notna().sum()}/{rst_df.dets.isna().sum()} images interpolated\")\n",
    "        return rst_df\n",
    "\n",
    "\n",
    "    def save_newAnnotations(self, df, save_path):\n",
    "        if osp.isdir(save_path) == False:\n",
    "            os.mkdir(save_path)\n",
    "            \n",
    "        new_annotes = df.loc[df['final_pred'].notnull()].index\n",
    "        for image in new_annotes:\n",
    "            new_preds = df._get_value(image, 'final_pred')\n",
    "            assert type(new_preds) != float\n",
    "            with open(save_path + image[:-4] + '.txt', 'w') as f:\n",
    "                for pred_det in new_preds:\n",
    "                    f.write(f\"{int(pred_det[-1])} {pred_det[0]} {pred_det[1]} {pred_det[2]} {pred_det[3]}\\n\")\n",
    "\n",
    "\n",
    "    def execute(self, tracking_valid_iou = 0.5, interpolate_count = 10, recursive = True):\n",
    "        df, image_shape = self.prepare_Detection_df(recursive = recursive)\n",
    "        ocsort_tracker_forward, ocsort_tracker_backward = self.create_ocSort_tracker()\n",
    "        \n",
    "        temp_df1 = self.interpolate(ocsort_tracker_forward, df, direction='forward', interpolate_count = interpolate_count, \n",
    "                                    tracking_valid_iou = tracking_valid_iou, image_shape=image_shape)\n",
    "        temp_df2 = self.interpolate(ocsort_tracker_backward, temp_df1, direction='backward', interpolate_count = interpolate_count,\n",
    "                                    tracking_valid_iou = tracking_valid_iou, image_shape=image_shape)\n",
    "        final_df  = self.update_autoAnnotate(temp_df2, tracking_valid_iou)\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8f2334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del obj\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15006871",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '/home/super/endoai/ugeon/autoAnnotation/testSet/V1697_p5_AD/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a3a8ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1379 images / shape : 1240x1080\n"
     ]
    }
   ],
   "source": [
    "tracking_valid_iou = 0.1\n",
    "interpolate_count = 10\n",
    "\n",
    "obj = autoAnnotate(dataset_path = dataset_path)\n",
    "ocsort_tracker_forward, ocsort_tracker_backward = obj.create_ocSort_tracker()\n",
    "df, image_shape = obj.prepare_Detection_df()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a24a40ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1379 images / shape : 1240x1080\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a776f0f4ecc7407e8fee801deb4e479f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe6234ead6e4cf0b1c15537fba523fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1379 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/295 images interpolated\n"
     ]
    }
   ],
   "source": [
    "rst = obj.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4491f951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>dets</th>\n",
       "      <th>pred_forward</th>\n",
       "      <th>pred_backward</th>\n",
       "      <th>final_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_01379.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_01378.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_01377.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_01376.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_01375.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_00005.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_00004.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_00003.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_00002.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1697_p5_AD_00001.jpg</th>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    path dets  \\\n",
       "image                                                                           \n",
       "V1697_p5_AD_01379.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_01378.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_01377.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_01376.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_01375.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "...                                                                  ...  ...   \n",
       "V1697_p5_AD_00005.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_00004.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_00003.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_00002.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "V1697_p5_AD_00001.jpg  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN   \n",
       "\n",
       "                      pred_forward pred_backward final_pred  \n",
       "image                                                        \n",
       "V1697_p5_AD_01379.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_01378.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_01377.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_01376.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_01375.jpg          NaN           NaN        NaN  \n",
       "...                            ...           ...        ...  \n",
       "V1697_p5_AD_00005.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_00004.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_00003.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_00002.jpg          NaN           NaN        NaN  \n",
       "V1697_p5_AD_00001.jpg          NaN           NaN        NaN  \n",
       "\n",
       "[1379 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad38fb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0.45367,       0.562,       0.148,      0.1503,           0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rst.loc['V1697_p5_AD_01365.jpg', 'final_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27675e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4a79b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6536481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b04794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d2949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974db12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4c62de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1379 images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>path</th>\n",
       "      <th>dets</th>\n",
       "      <th>pred_forward</th>\n",
       "      <th>pred_backward</th>\n",
       "      <th>final_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V1697_p5_AD_00001.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V1697_p5_AD_00002.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V1697_p5_AD_00003.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V1697_p5_AD_00004.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V1697_p5_AD_00005.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>V1697_p5_AD_01375.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>V1697_p5_AD_01376.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>V1697_p5_AD_01377.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>V1697_p5_AD_01378.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>V1697_p5_AD_01379.jpg</td>\n",
       "      <td>/home/super/endoai/ugeon/autoAnnotation/testSe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1379 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      image  \\\n",
       "0     V1697_p5_AD_00001.jpg   \n",
       "1     V1697_p5_AD_00002.jpg   \n",
       "2     V1697_p5_AD_00003.jpg   \n",
       "3     V1697_p5_AD_00004.jpg   \n",
       "4     V1697_p5_AD_00005.jpg   \n",
       "...                     ...   \n",
       "1374  V1697_p5_AD_01375.jpg   \n",
       "1375  V1697_p5_AD_01376.jpg   \n",
       "1376  V1697_p5_AD_01377.jpg   \n",
       "1377  V1697_p5_AD_01378.jpg   \n",
       "1378  V1697_p5_AD_01379.jpg   \n",
       "\n",
       "                                                   path dets pred_forward  \\\n",
       "0     /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "1     /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "2     /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "3     /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "4     /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "...                                                 ...  ...          ...   \n",
       "1374  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "1375  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "1376  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "1377  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "1378  /home/super/endoai/ugeon/autoAnnotation/testSe...  NaN          NaN   \n",
       "\n",
       "     pred_backward final_pred  \n",
       "0              NaN        NaN  \n",
       "1              NaN        NaN  \n",
       "2              NaN        NaN  \n",
       "3              NaN        NaN  \n",
       "4              NaN        NaN  \n",
       "...            ...        ...  \n",
       "1374           NaN        NaN  \n",
       "1375           NaN        NaN  \n",
       "1376           NaN        NaN  \n",
       "1377           NaN        NaN  \n",
       "1378           NaN        NaN  \n",
       "\n",
       "[1379 rows x 6 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = sorted(glob(dataset_path + '**/*.jpg', recursive = True))\n",
    "img_path_dict = {osp.basename(f) : f for f in images}\n",
    "img_annote_dict = dict()\n",
    "for image in images:\n",
    "    image_shape = list(map(int, re.findall('(\\d+)x(\\d+)', magic.from_file(images[0]))[-1]))\n",
    "    img_name = image.split('/')[-1]\n",
    "    try :\n",
    "        with open(image[:-4]+ '.txt', 'r') as f:\n",
    "            temp = np.asarray(list(map(lambda x: list(np.float64(x.strip().split( ))), f.readlines())))\n",
    "            annotation = temp[:,1:]\n",
    "            annotation = np.append(annotation, temp[:,0]).reshape(1,5)\n",
    "            annotation = xywh2xyxy(annotation, image_shape)\n",
    "            annotation[:,:4] = annotation[:,:4] * [int(image_shape[0]), int(image_shape[1]),int(image_shape[0]), int(image_shape[1])]\n",
    "            img_annote_dict[img_name]= annotation\n",
    "\n",
    "    except :\n",
    "        img_annote_dict[img_name]= np.nan\n",
    "df = pd.DataFrame(columns = ['image', 'path','dets', 'pred_forward', 'pred_backward', 'final_pred'])\n",
    "df['image'] = img_path_dict.keys()\n",
    "df['path'] = df['image'].apply(lambda x : img_path_dict[x])\n",
    "df['dets'] = df['image'].apply(lambda x : img_annote_dict[x])\n",
    "print(f\"found {len(df)} images\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998e9a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5a25a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
