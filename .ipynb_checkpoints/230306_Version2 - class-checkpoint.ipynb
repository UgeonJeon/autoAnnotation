{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb23bfe4",
   "metadata": {},
   "source": [
    "* 1C : two track으로 적용 후 interpolate prediction을 우선으로 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6f3b7d",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f1ebdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T05:23:14.872708Z",
     "start_time": "2023-03-06T05:23:13.967135Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from glob import glob \n",
    "import os.path as osp\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import pathlib\n",
    "import sys\n",
    "import ast\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import magic\n",
    "import re\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/ugeon/endoai/jupyter/autoAnnotation/ocSort/')\n",
    "from ocSort.trackers.ocsort.ocsort import OCSort\n",
    "\n",
    "sys.path.append('/home/ugeon/.local/lib/python3.8/site-packages')\n",
    "sys.path.append('/home/ugeon/endoai/jupyter/module/')\n",
    "from preprocessingData_v3 import verify_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6aab0e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T05:23:14.883399Z",
     "start_time": "2023-03-06T05:23:14.874528Z"
    }
   },
   "outputs": [],
   "source": [
    "def xywh2xyxy(x, image_shape = False):\n",
    "    \"\"\"\n",
    "    image_shape = (width, height)\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray)):\n",
    "        x = np.array(x)\n",
    "\n",
    "    # Convert nx4 boxes from [cx, cy, w, h, cls] to [x1, y1, x2, y2, cls] where xy1=top-left, xy2=bottom-right\n",
    "    y = np.copy(x)\n",
    "    y[:, 0] = x[:, 0] - x[:, 2] / 2  # top left x\n",
    "    y[:, 1] = x[:, 1] - x[:, 3] / 2  # top left y\n",
    "    y[:, 2] = x[:, 0] + x[:, 2] / 2  # bottom right x\n",
    "    y[:, 3] = x[:, 1] + x[:, 3] / 2  # bottom right y\n",
    "    \n",
    "    if image_shape:\n",
    "        y[:,:4] = y[:,:4] * [int(image_shape[0]), int(image_shape[1]),int(image_shape[0]), int(image_shape[1])]\n",
    "    return y\n",
    "\n",
    "\n",
    "def xyxy2xywh(x, image_shape = False):\n",
    "    \"\"\"\n",
    "    image_shape = (width, height)\n",
    "    \"\"\"\n",
    "    if not isinstance(x, (np.ndarray)):\n",
    "        x = np.array(x)\n",
    "\n",
    "    # Convert nx4 boxes from [x1, y1, x2, y2, cls] to [cx, cy, w, h, cls]\n",
    "    y = np.copy(x)\n",
    "    y[:, 0] = (x[:, 0] + x[:, 2]) / 2  # center x\n",
    "    y[:, 1] = (x[:, 1] + x[:, 3]) / 2  # center y\n",
    "    y[:, 2] = (x[:, 2] - x[:, 0])         # width x\n",
    "    y[:, 3] = (x[:, 3] - x[:, 1])        # width y\n",
    "\n",
    "    if image_shape:    \n",
    "        y[:,:4] = y[:,:4] / [int(image_shape[0]), int(image_shape[1]),int(image_shape[0]), int(image_shape[1])]\n",
    "    return y\n",
    "\n",
    "\n",
    "def IoU( box1, box2):\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "\n",
    "    # obtain x1, y1, x2, y2 of the intersection\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # compute the width and height of the intersection\n",
    "    w = max(0, x2 - x1 + 1)\n",
    "    h = max(0, y2 - y1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    iou = inter / (box1_area + box2_area - inter)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def calculateZOOM(img1, img2, scale_factor = 0.7):\n",
    "    small1 = cv2.resize(img1, None, fx=scale_factor, fy=scale_factor)\n",
    "    small2 = cv2.resize(img2, None, fx=scale_factor, fy=scale_factor)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray1 = cv2.cvtColor(small1, cv2.COLOR_BGR2GRAY)\n",
    "    gray2 = cv2.cvtColor(small2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect keypoints and compute the ORB descriptors\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(gray1, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(gray2, None)\n",
    "\n",
    "    # Match the descriptors\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "\n",
    "    # Sort the matches in the order of their distances\n",
    "    matches = sorted(matches, key = lambda x : x.distance)\n",
    "\n",
    "    # Calculate the zoom level\n",
    "    if len(matches) > 4:\n",
    "        src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "        zoom = np.abs(np.linalg.det(M))\n",
    "    return zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5ad432d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T05:27:20.279287Z",
     "start_time": "2023-03-06T05:27:20.276530Z"
    }
   },
   "outputs": [],
   "source": [
    "del autoAnnotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e9823c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T06:04:42.292858Z",
     "start_time": "2023-03-06T06:04:42.271845Z"
    }
   },
   "outputs": [],
   "source": [
    "class autoAnnotate:\n",
    "    \n",
    "    def __init__(self, dataset_path, recursive):\n",
    "        self.dataset_path = dataset_path\n",
    "        self.recursive = recursive\n",
    "\n",
    "    def prepare_Detection_df(self):\n",
    "        \"\"\"\n",
    "        caution! Only Available for jpg images\n",
    "        dets = [cx, cy, w, h, 1(conf), cls]\n",
    "        dets_xyxy = [x1, y1, x2, y2, 1(conf), cls]\n",
    "        \"\"\"\n",
    "        images = sorted(glob(self.dataset_path + '**/*.jpg', recursive = self.recursive))\n",
    "        img_path_dict = {osp.basename(f) : f for f in images}\n",
    "        annote_dict = dict()\n",
    "        annote_xyxy_dict = dict()\n",
    "        image_shape = list(map(int, re.findall('(\\d+)x(\\d+)', magic.from_file(images[0]))[-1]))\n",
    "\n",
    "        for image in images:\n",
    "            img_name = image.split('/')[-1]\n",
    "            try :\n",
    "                with open(image[:-4]+ '.txt', 'r') as f:\n",
    "                    temp = np.asarray(list(map(lambda x: list(np.float64(x.strip().split( )))+ [1], f.readlines())))\n",
    "                    annotation = temp[:,1:]\n",
    "                    annotation = np.append(annotation, temp[:,0]).reshape(1,6)\n",
    "\n",
    "                    annotation_xyxy = xywh2xyxy(annotation, image_shape)\n",
    "                    annote_dict[img_name] = annotation\n",
    "                    annote_xyxy_dict[img_name]= annotation_xyxy\n",
    "            except :\n",
    "                annote_xyxy_dict[img_name]= np.nan\n",
    "                annote_dict[img_name] = np.nan\n",
    "\n",
    "        df = pd.DataFrame(columns = ['image', 'path','dets', 'dets_xyxy', 'tracker_forward', 'tracker_backward', 'tracker_rst', 'interpolate_rst', 'final_pred'])  \n",
    "        df['image'] = img_path_dict.keys()\n",
    "        df['path'] = df['image'].apply(lambda x : img_path_dict[x])\n",
    "        df['dets'] = df['image'].apply(lambda x : annote_dict[x])\n",
    "        df['dets_xyxy'] = df['image'].apply(lambda x : annote_xyxy_dict[x])\n",
    "        print(f\"found {len(df)} images / shape : {image_shape[0]}x{image_shape[1]}\")\n",
    "        return df, image_shape\n",
    "\n",
    "\n",
    "    def get_properDets(self, prev_dets, new_dets, tracking_valid_iou):\n",
    "        \"\"\"\n",
    "        prev_dets, new_dets 라벨링1:1 매칭해 prev_dets와 tracking_valid_iou 이상인 new_dets만 남김\n",
    "        \"\"\"\n",
    "        valid_idx = []\n",
    "        for idx, prev_det in enumerate(prev_dets):\n",
    "            for new_det in new_dets:\n",
    "                iou = IoU(new_det, prev_det)\n",
    "                if iou >= tracking_valid_iou:\n",
    "                    valid_idx.append(idx)\n",
    "        valid_idx = list(set(valid_idx))\n",
    "        valid_prev_dets = prev_dets[valid_idx]\n",
    "        return valid_prev_dets\n",
    "\n",
    "    \n",
    "    # predict with tracker\n",
    "    def create_ocSort_tracker(self):\n",
    "        ocsort_forward = OCSort(det_thresh = 0.1, iou_threshold = 0.1, min_hits = 1, delta_t = 7,)\n",
    "        ocsort_backward = OCSort(det_thresh = 0.1, iou_threshold = 0.1, min_hits = 1, delta_t = 7,)\n",
    "        return ocsort_forward, ocsort_backward\n",
    "\n",
    "\n",
    "    def predictDet(self, tracker, df, direction, tracking_valid_iou, pred_count, image_shape):\n",
    "        \"\"\"\n",
    "        direction : forward, backward\n",
    "        \"\"\"\n",
    "        if direction  == 'forward':\n",
    "            out_df = df.sort_values(by = 'image', ascending = True)\n",
    "        elif direction  == 'backward':\n",
    "            out_df = df.sort_values(by = 'image', ascending = False)\n",
    "\n",
    "        predictable_state = False\n",
    "        prev_Detected = False\n",
    "        prev_img = None\n",
    "        prev_TrueDets = None\n",
    "        prev_TrueDets_xywh = None\n",
    "        zoom_factor = []\n",
    "        predDet_count = 1\n",
    "        interpolate_det_count = 0\n",
    "\n",
    "        for idx in tqdm(out_df.index):\n",
    "            image_name = out_df._get_value(idx, 'image')\n",
    "            det = out_df._get_value(idx, 'dets_xyxy')\n",
    "            img_path = out_df._get_value(idx, 'path')\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            if isinstance(det, (np.ndarray)) :\n",
    "                if prev_Detected == False:\n",
    "                    prev_Detected = True\n",
    "                    predictable_state = False\n",
    "                elif prev_Detected:\n",
    "                    predictable_state = True\n",
    "\n",
    "                prev_img = img\n",
    "                prev_TrueDets = det\n",
    "                prev_TrueDets_xywh = xyxy2xywh(det, image_shape)\n",
    "                predDet_count = 1\n",
    "                zoom_factor = []\n",
    "                tracker.update(det,img)\n",
    "            else :\n",
    "                det = np.empty((0, 6))\n",
    "                pred_dets = tracker.update(det,img, return_predict = True)\n",
    "                pred_dets = self.get_properDets(pred_dets, prev_TrueDets, tracking_valid_iou)\n",
    "\n",
    "                if predictable_state and predDet_count < pred_count + 1 and len(pred_dets) >=1:\n",
    "                    zoom = calculateZOOM(prev_img, img)\n",
    "                    zoom_factor.append(zoom)\n",
    "                    if zoom >= 0.6 and zoom <= 1.6:\n",
    "                        pred_dets_xywh = xyxy2xywh(pred_dets, image_shape)\n",
    "                        pred_dets_xywh[:,2] = prev_TrueDets_xywh[:,2].max() * np.mean(zoom_factor)\n",
    "                        pred_dets_xywh[:,3] = prev_TrueDets_xywh[:,3].max() * np.mean(zoom_factor)\n",
    "                        out_df._set_value(idx, f'tracker_{direction}', pred_dets_xywh)        \n",
    "                        predDet_count += 1\n",
    "                        interpolate_det_count += 1\n",
    "                    else:\n",
    "                        predictable_state = False\n",
    "                        zoom_factor = []\n",
    "\n",
    "                prev_img = img\n",
    "                prev_Detected = False\n",
    "\n",
    "        if direction  == 'backward':\n",
    "            out_df = out_df.sort_values(by = 'image', ascending=True)\n",
    "        return out_df\n",
    "\n",
    "\n",
    "    def update_predDet(self, rst_df, tracking_valid_iou):\n",
    "        out_df = rst_df.copy()\n",
    "        part_images = out_df.loc[(out_df['tracker_forward'].notna())|(out_df['tracker_backward'].notna())].index\n",
    "        for idx in part_images:\n",
    "            pred1 = out_df._get_value(idx, 'tracker_forward')\n",
    "            pred2 = out_df._get_value(idx, 'tracker_backward')\n",
    "\n",
    "            if type(pred1) == float:\n",
    "                out_df._set_value(idx, 'tracker_rst', pred2)\n",
    "            elif type(pred2) == float:\n",
    "                out_df._set_value(idx, 'tracker_rst', pred1)\n",
    "            elif len(pred1) == 1 and len(pred2) == 1: \n",
    "                iou = IoU(pred1[0], pred2[0])\n",
    "                if iou >= tracking_valid_iou:\n",
    "                    new_pred = (pred1  + pred2)/2\n",
    "                    out_df._set_value(idx, 'tracker_rst', new_pred)\n",
    "                else:\n",
    "                    continue\n",
    "        out_df = out_df.sort_values(by = 'image', ascending=True)\n",
    "        return out_df\n",
    "\n",
    "    \n",
    "    # interpolate\n",
    "    def interpolate_indexList(self, df, interpolate_count):\n",
    "        \"\"\"\n",
    "         : 어떤 column을 기준으로 interpolate할 것인지 지정\n",
    "        2프레임 연속으로 det이 존재해야 interpolate 가능\n",
    "        \"\"\"\n",
    "        part_df = df[['image','dets']].copy()\n",
    "\n",
    "        empty_idx_list = list(df.loc[df['dets'].isna()].index)\n",
    "        part_df['prev_dets'] = part_df['dets'].shift(1)\n",
    "        part_df['next_dets'] = part_df['dets'].shift(-1)\n",
    "        interpolatable_idx_list = list(part_df.loc[(part_df['dets'].notna())&((part_df['prev_dets'].notna())|(part_df['next_dets'].notna()))].index)\n",
    "\n",
    "        idx = 0\n",
    "        prev_i = False\n",
    "        rtn_dict = dict()\n",
    "        temp_list = []\n",
    "        rtn_list = []\n",
    "\n",
    "        for i in empty_idx_list:\n",
    "            if not prev_i:\n",
    "                temp_list.append(i)\n",
    "                prev_i = i\n",
    "                continue\n",
    "            if i - prev_i == 1:\n",
    "                temp_list.append(i)\n",
    "                prev_i = i\n",
    "            else:\n",
    "                prev_i = i\n",
    "                if len(temp_list) <= interpolate_count:\n",
    "                    min_idx = min(temp_list) - 1\n",
    "                    max_idx = max(temp_list) + 1\n",
    "                    if min_idx in interpolatable_idx_list and max_idx in interpolatable_idx_list:\n",
    "                        rtn_list.append(min_idx)\n",
    "                        rtn_list.append(max_idx)\n",
    "                temp_list = [i]\n",
    "        del part_df\n",
    "        return rtn_list\n",
    "\n",
    "    \n",
    "    def interpolateDet(self, df, interpolate_count):\n",
    "        \"\"\"\n",
    "        return shape : (1, 5)\n",
    "        interpolate detections with arithmetic sequence(등차수열)\n",
    "            2프레임 연속으로 det이 존재해야 interpolate 가능\n",
    "         : 어떤 column을 기준으로 interpolate할 것인지 지정\n",
    "        interpolate_count : interpolate할 최대 연속된 빈칸; ex) 30프레임 이상 연속되게 비어있는 경우 interpolate하지 않음\n",
    "        \"\"\"\n",
    "        out_df = df.copy()\n",
    "        ipt_list = self.interpolate_indexList(out_df, interpolate_count)\n",
    "\n",
    "        for idx in range(len(ipt_list) // 2):\n",
    "            start_idx = ipt_list[2 * idx]\n",
    "            end_idx = ipt_list[2 * idx + 1]\n",
    "\n",
    "            start_det = out_df._get_value(start_idx,'dets')\n",
    "            end_det = out_df._get_value(end_idx, 'dets')\n",
    "            if len(start_det) == 1 and len(end_det) == 1:\n",
    "                diff_det = (end_det - start_det) / (end_idx - start_idx)\n",
    "                dcx, dcy, dw, dh =  diff_det[0][0], diff_det[0][1], diff_det[0][2], diff_det[0][3]\n",
    "\n",
    "                for mv_idx, df_idx in enumerate(range(start_idx + 1, end_idx)):\n",
    "                    new_cx = start_det[:,0] + dcx * (mv_idx + 1)\n",
    "                    new_cy = start_det[:,1] + dcy * (mv_idx + 1)\n",
    "                    new_w = start_det[:,2] + dw * (mv_idx + 1)\n",
    "                    new_h = start_det[:,3] + dh * (mv_idx + 1)\n",
    "                    new_det = f\"{new_cx[0]} {new_cy[0]} {new_w[0]} {new_h[0]} 1 0\"\n",
    "                    new_det2 = np.array([list(map(lambda x : np.float64(x), new_det.split()))])\n",
    "                    out_df._set_value(df_idx, 'interpolate_rst', new_det2)\n",
    "        return out_df\n",
    "    \n",
    "\n",
    "    def merge_finalDet(self, rst_df, merge_valid_iou):\n",
    "        out_df = rst_df.copy()\n",
    "        part_images = out_df.loc[(out_df['tracker_rst'].notna())|(out_df['interpolate_rst'].notna())].index\n",
    "        for idx in part_images:\n",
    "            pred1 = out_df._get_value(idx, 'tracker_rst')\n",
    "            pred2 = out_df._get_value(idx, 'interpolate_rst')\n",
    "\n",
    "            if type(pred1) == float:\n",
    "                out_df._set_value(idx, 'final_pred', pred2)\n",
    "            elif type(pred2) == float:\n",
    "                out_df._set_value(idx, 'final_pred', pred1)\n",
    "            elif len(pred1) == 1 and len(pred2) == 1: \n",
    "                iou = IoU(pred1[0], pred2[0])\n",
    "                if iou >= merge_valid_iou:\n",
    "                    _, new_pred = verify_annotation(pred2)\n",
    "                    out_df._set_value(idx, 'final_pred', new_pred)\n",
    "                else:\n",
    "                    new_pred = np.vstack((pred1  + pred2))\n",
    "                    _, new_pred = verify_annotation(new_pred)\n",
    "                    out_df._set_value(idx, 'final_pred', new_pred)\n",
    "\n",
    "        print(f\"{out_df['final_pred'].notna().sum()}/{out_df['dets'].isna().sum()} blank images auto-annotated\")\n",
    "        print(f\"    tracker {out_df['tracker_rst'].notna().sum()} / interpolate {out_df['interpolate_rst'].notna().sum()}\")\n",
    "        out_df = out_df.sort_values(by = 'image', ascending=True)\n",
    "        return out_df\n",
    "    \n",
    "    \n",
    "    def save_newAnnotations(self, df, col_name, save_path):\n",
    "        if osp.isdir(save_path) == False:\n",
    "            os.mkdir(save_path)\n",
    "\n",
    "        new_annotes = df.loc[df[col_name].notnull()].index\n",
    "        for idx in new_annotes:\n",
    "            imageName = df._get_value(idx, 'image')\n",
    "            temp_new = df._get_value(idx, col_name)\n",
    "            tmpe_new2 = temp_new[:,:4]\n",
    "            tmpe_new2 = np.append(temp_new[:,-1], tmpe_new2).reshape(1,5)\n",
    "            ret, new_preds = verify_annotation(tmpe_new2)\n",
    "\n",
    "            if ret != 'error':\n",
    "                with open(save_path + imageName[:-4] + '.txt', 'w') as f:\n",
    "                    for pred_det in new_preds.tolist():\n",
    "                        to_write = f\"{int(pred_det[0])} {pred_det[1]} {pred_det[2]} {pred_det[3]} {pred_det[4]}\\n\"\n",
    "                        f.write(to_write)\n",
    "\n",
    "\n",
    "    def execute(self, tracking_valid_iou = 0.2, merge_valid_iou = 0.6, pred_count = 20, interpolate_count = 20):\n",
    "        \"\"\"\n",
    "        tracking_valid_iou = tracker_forward와 tracker_backward를 비교할 IOU\n",
    "        merge_valid_iou = tracker와 interpolate를 비교할 IOU\n",
    "        pred_count = tracker을 이용해 predict할 프레임 수 \n",
    "        interpolate_count = interpolate할 최대 연속된 빈 detection; ex) 30프레임 이상 연속되게 비어있는 경우 interpolate하지 않음\n",
    "        \"\"\"\n",
    "        df, image_shape = self.prepare_Detection_df()\n",
    "        ocsort_tracker_forward, ocsort_tracker_backward = self.create_ocSort_tracker()\n",
    "\n",
    "        tacker_df1 = self.predictDet(ocsort_tracker_forward, df, direction='forward', pred_count = pred_count, \n",
    "                                    tracking_valid_iou = tracking_valid_iou, image_shape=image_shape)\n",
    "        tacker_df2 = self.predictDet(ocsort_tracker_backward, tacker_df1, direction='backward', pred_count = pred_count,\n",
    "                                    tracking_valid_iou = tracking_valid_iou, image_shape=image_shape)\n",
    "        tracker_rst_df  = self.update_predDet(tacker_df2, tracking_valid_iou)\n",
    "        \n",
    "        interpolate_rst_df = self.interpolateDet(tracker_rst_df, interpolate_count)\n",
    "        \n",
    "        result_df = self.merge_finalDet(interpolate_rst_df, merge_valid_iou)\n",
    "        \n",
    "        return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3080c5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T06:04:43.320526Z",
     "start_time": "2023-03-06T06:04:43.317161Z"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_path = '/mnt/d/autoAnnotate/testSet/V1516_p1_AD/'\n",
    "dataset_path = '/mnt/d/autoAnnotate/testSet/V1660_p1_AD/'\n",
    "pno = dataset_path.split('/')[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2eb49f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-06T06:10:55.149865Z",
     "start_time": "2023-03-06T06:09:56.620033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1829 images / shape : 1240x1080\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00818777084350586,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 75,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1829,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3df975d3f27840c7a4946e524ad97557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1829 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.008229732513427734,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 75,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1829,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1892f90a04db495b956f586f6b5666f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1829 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453/1308 blank images auto-annotated\n",
      "    tracker 445 / interpolate 116\n"
     ]
    }
   ],
   "source": [
    "tracking_valid_iou = 0.2\n",
    "merge_valid_iou = 0.6\n",
    "pred_count = 15\n",
    "interpolate_count = 30\n",
    "\n",
    "obj = autoAnnotate(dataset_path, recursive=True)\n",
    "\n",
    "rst_df = obj.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11cc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c3b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db653019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62929a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1797306a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ca06f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da055a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4408d10f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
